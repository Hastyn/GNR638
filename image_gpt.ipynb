{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHc7YALSuS9C"
      },
      "source": [
        "# Link to the other notebook :\n",
        "## Coding is finished preliminarily, just train it now\n",
        "https://colab.research.google.com/drive/148yiVLIHWIv9r9GNDLALyG-9EgL7aUFT?usp=sharing\n",
        "\n",
        "(Shift to the above notebook)  \n",
        "(Don't use the current one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1sS7sIFicsm"
      },
      "source": [
        "## Image GPT\n",
        " * Paper Link : https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf\n",
        "\n",
        " * Here, we will try to improve the transformer to make it work satisfactorily in lower complexities\n",
        "\n",
        " * Even the smallest model iGPT-S has 76M parameters, so we can try bringing it down to say 30M or less.\n",
        "\n",
        " * Datasets used will be mainly :\n",
        "  - Tiny ImageNet\n",
        "  - CIFAR 10 & CIFAR 100\n",
        "\n",
        " * The model's code is present below but utils.py and run.py are yet to be covered.\n",
        "\n",
        " * This is just a preliminary sketch, please continue further\n",
        "\n",
        "### Thanks for cooperation\n",
        "\n",
        "## PS :\n",
        "GPT - 2 Paper : https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf  \n",
        "GPT Paper : https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf  \n",
        "\n",
        "<hr />\n",
        "\n",
        "Ye Paper bhi dekh lo : https://arxiv.org/pdf/1802.05751.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG9vq1fCNJY8"
      },
      "source": [
        "### The Transformer Architecture  \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1838/1*BHzGVskWGS_3jEcYYi6miQ.png\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fy1p_xdft8"
      },
      "source": [
        "## The GPT-2 Decoder Only Architecture  \n",
        "<img src=\"https://i.stack.imgur.com/Kb8Gq.png\" height=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug2US-FLto-m"
      },
      "source": [
        "## Attention :  \n",
        "<img src=\"https://ryanong.co.uk/wp-content/uploads/2020/01/Attention-formula.png\" width=500 />  \n",
        "<br />\n",
        "\n",
        "Q = Query  \n",
        "K = Key  \n",
        "V = Value  \n",
        "\n",
        "d_k = Embedding dimension  \n",
        "\n",
        "Transformer Architecture details : [Ari Seff's Video](https://www.youtube.com/watch?v=XSSTuhyAmnI&list=PLcwMiqcoGw1WiEobtKcPOU7A4iePwOZH_&index=17&t=421s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpMe7wWAZF2z"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy-3cc6709n7",
        "outputId": "61d7f5fd-d423-433b-b6de-2e9f8f60bd33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "\n",
        "# This module has been deprecated. Please find out an alternative.\n",
        "\n",
        "# Update : Temporarily used another module from this link :\n",
        "# https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.training import HParams\n",
        "\n",
        "# Default Hyperparameters\n",
        "def default_hparams():\n",
        "    return HParams(\n",
        "        n_vocab=0,\n",
        "        n_ctx=1024,\n",
        "        n_embd=768,\n",
        "        n_head=12,\n",
        "        n_layer=12,\n",
        "    )\n",
        "\n",
        "def shape_list(x):\n",
        "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
        "    static = x.shape.as_list()\n",
        "    dynamic = tf.shape(x)\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    x = x - tf.reduce_max(x, axis=axis, keepdims=True)\n",
        "    ex = tf.exp(x)\n",
        "    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "def gelu(x):\n",
        "  \"\"\"Gaussian Error Linear Unit : Combines activation function with\n",
        "                                  dropout regularization\n",
        "     Paper Link : https://arxiv.org/pdf/1606.08415v3.pdf\n",
        "     https://medium.com/@shoray.goel/gelu-gaussian-error-linear-unit-4ec59fb2e47c\"\"\"\n",
        "\n",
        "  return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "def gelu2(x):\n",
        "  \"\"\"Another approximation of the GELU function\n",
        "     Link : https://paperswithcode.com/method/gelu\"\"\"\n",
        "\n",
        "  return x * tf.sigmoid(1.702 * x)\n",
        "\n",
        "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
        "  \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform\"\"\"\n",
        "\n",
        "  \"\"\"Affine transformation : https://en.wikipedia.org/wiki/Affine_transformation\"\"\"\n",
        "\n",
        "  \"\"\"The asterisk in a function definition forces the caller to provide named arguments.\n",
        "   See the link if still confused.\n",
        "   https://stackoverflow.com/questions/14301967/bare-asterisk-in-function-arguments\"\"\"\n",
        "\n",
        "  with tf.compat.v1.variable_scope(scope):\n",
        "    n_state = x.shape[axis].value\n",
        "    g = tf.compat.v1.get_variable('g', [n_state], initializer=tf.constant_initializer(1))\n",
        "\n",
        "    # tf.compat.v1.get_variable obtains the variable passed as first argument\n",
        "    # if it was already present, else creates a new one\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/compat/v1/get_variable\n",
        "\n",
        "    s = tf.reduce_mean(tf.square(x), axis=axis, keepdims=True)\n",
        "    x = x*tf.math.rsqrt(s + epsilon)     # Reciprocal of the sqrt, elementwise\n",
        "    x =  x*g                        # Probably increasing the dimension here; I didn't understand exactly\n",
        "                                    # Might be the diagonal transformation\n",
        "\n",
        "\n",
        "    # Where did we recenter it to mean = 0?\n",
        "    return x\n",
        "\n",
        "def split_states(x, n):\n",
        "  \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n]\"\"\"\n",
        "  *start, m = shape_list(x)\n",
        "  return tf.reshape(x, start + [n, m//n])\n",
        "\n",
        "def merge_states(x):\n",
        "  \"\"\"Smash the last two dimensions of x into a single dimension\"\"\"\n",
        "  *start, a, b = shape_list(x)\n",
        "  return tf.reshape(x, start+[a*b])\n",
        "\n",
        "# scope is a string, tf.compat.v1.variable_scope(scope) will automatically concat this string\n",
        "# to all the variable names in that block to prevent name overlap\n",
        "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
        "  with tf.compat.v1.variable_scope(scope):\n",
        "    *start, nx = shape_list(x)\n",
        "    # w = array of weights\n",
        "\n",
        "    w = tf.compat.v1.get_variable('w', [nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))\n",
        "\n",
        "    # Convolution operation\n",
        "    c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf])), start+[nf])\n",
        "    return c\n",
        "\n",
        "def attention_mask(nd, ns, *, dtype):\n",
        "  \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
        "\n",
        "  Same as tf.matrix_band_part(tf.ones[nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\"\"\"\n",
        "\n",
        "  \"\"\"Example : attention_mask(2, 4, tf.uint8) returns [[1 1 1 0]\n",
        "                                                       [1 1 1 1]]\"\"\"\n",
        "\n",
        "  i = tf.range(nd)[:, None]\n",
        "  j = tf.range(ns)\n",
        "  m = i >= j - ns + nd\n",
        "\n",
        "  return tf.cast(m, dtype)\n",
        "\n",
        "\n",
        "# What is n_state?\n",
        "def attn(x, scope, n_state, *, past, hparams):\n",
        "  \"\"\"Returns the attention vector along with present key, value matrices\"\"\"\n",
        "  assert x.shape.ndims == 3   # [batch, sequence, features]\n",
        "  assert n_state % hparams.n_head == 0\n",
        "\n",
        "  if past is not None:\n",
        "    assert past.shape.ndims == 5  # [batch, 2, heads, sequence, features], where 2 is [k, v]\n",
        "\n",
        "  def split_heads(x):\n",
        "    # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
        "\n",
        "    return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
        "\n",
        "  def merge_heads(x):\n",
        "    # Reverse of split_heads\n",
        "    return merge_states(tf.transpose(x, [0, 2, 1, 3]))\n",
        "\n",
        "  def mask_attn_weights(w):\n",
        "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
        "\n",
        "    \"\"\"nd = length of destination sequence probably,\n",
        "       ns = length of source sequence probably.\"\"\"\n",
        "    _, _, nd, ns = shape_list(w)\n",
        "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
        "    b = tf.reshape(b, [1, 1, nd, ns])\n",
        "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
        "    return w\n",
        "\n",
        "  def multihead_attn(q, k, v):\n",
        "    # q, k, v have shape [batch, heads, sequence, features]\n",
        "\n",
        "    # w is just a temporary variable\n",
        "    w = tf.matmul(q, k, transpose_b=True)   # QK^T\n",
        "\n",
        "    w = w * tf.math.rsqrt(tf.cast(v.shape[-1].value, w.dtype))  # QK^T/sqrt(d_k)\n",
        "\n",
        "    if not hparams.bert:\n",
        "        w = mask_attn_weights(w)   # This is because GPT-2 uses self-attention mask\n",
        "    w = softmax(w)\n",
        "    attention = tf.matmul(w, v)\n",
        "    return attention\n",
        "\n",
        "  with tf.compat.v1.variable_scope(scope):\n",
        "    *start, nx = shape_list(x)\n",
        "\n",
        "    # The weight matrices for Q, K, V\n",
        "    wk = tf.compat.v1.get_variable(\"k_proj\", [hparams.n_head, nx // hparams.n_head, n_state], initializer=tf.random_normal_initializer(stddev=1.0/np.sqrt(n_state)))\n",
        "    wq = tf.compat.v1.get_variable(\"q_proj\", [hparams.n_head, nx // hparams.n_head, n_state], initializer=tf.random_normal_initializer(stddev=1.0/np.sqrt(n_state)))\n",
        "    wv = tf.compat.v1.get_variable(\"v_proj\", [hparams.n_head, nx // hparams.n_head, n_state], initializer=tf.random_normal_initializer(stddev=1.0/np.sqrt(n_state)))\n",
        "\n",
        "\n",
        "    \"\"\"This is Einstein summation. Prof. Raghav Verma taught it briefly if you recall.\n",
        "       Anyways, the link is here : https://www.tensorflow.org/api_docs/python/tf/einsum\n",
        "\n",
        "       Basically, matrix multiplication in shorthand notations.\n",
        "\n",
        "       If Cik = sum_j Aij*Bjk,\n",
        "       then, the string will be :\n",
        "       ij,jk->ik\n",
        "\n",
        "       As simple as this.\"\"\"\n",
        "\n",
        "    \"\"\"b = batch, s = sequence, f = feature, h = head, e = embedding\"\"\"\n",
        "    k = tf.einsum(\"bsf,hef->bhse\", x, wk)\n",
        "    q = tf.einsum(\"bsf,hef->bhse\", x, wq)\n",
        "    v = tf.einsum(\"bsf,hef->bhse\", x, wv)\n",
        "\n",
        "    present = tf.stack([k, v], axis=1)\n",
        "\n",
        "    if past is not None:\n",
        "      pk, pv = tf.unstack(past, axis=1)\n",
        "      k = tf.concat([pk, k], axis=-2)\n",
        "      v = tf.concat([pv, v], axis=-2)\n",
        "\n",
        "    a = multihead_attn(q, k, v)   # Calculation of attention\n",
        "\n",
        "    # The context weights (from the context vector C)\n",
        "    wc = tf.compat.v1.get_variable(\"c_proj\", [hparams.n_head, nx // hparams.n_head, n_state],\n",
        "                                   initializer=tf.random_normal_initializer(stddev=1.0/np.sqrt(n_state*hparams.n_layer)))\n",
        "\n",
        "    a = tf.einsum(\"bhse,hef->bsf\", a, wc)\n",
        "    return a, present\n",
        "\n",
        "def mlp(x, scope, n_state, *, hparams):\n",
        "  \"\"\"The feed forward layer inside a block\"\"\"\n",
        "  with tf.compat.v1.variable_scope(scope):\n",
        "    nx = x.shape[-1].value\n",
        "    h = gelu2(conv1d(x, 'c_fc', n_state))\n",
        "    h2 = conv1d(h, 'c_proj', nx)\n",
        "    return h2\n",
        "\n",
        "# One block of decoder. See the figure above\n",
        "def block(x, scope, *, past, hparams):\n",
        "  with tf.compat.v1.variable_scope(scope):\n",
        "    nx = x.shape[-1].value\n",
        "    a, present = attn(norm(x, 'ln_1'), 'attn', nx, past=past, hparams=hparams)\n",
        "    x = x+a\n",
        "    # Adding the attention to the original input (original input is kept to preserve residual characteristics)\n",
        "\n",
        "    m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
        "    x = x+m\n",
        "    # Feed forward layer along with residual connection\n",
        "\n",
        "    return x, present\n",
        "\n",
        "# I still need to understand the math here. Ain't familiar with the shapes\n",
        "def past_shape(*, hparams, batch_size=None, sequence=None):\n",
        "  return [batch_size, hparams.n_layer, 2, hparams.n_head, sequence, hparams.n_embd // hparams.n_head]\n",
        "\n",
        "def expand_tile(value, size):\n",
        "  \"\"\"Add a new axis of given size.\"\"\"\n",
        "\n",
        "  value = tf.convert_to_tensor(value, name='value')\n",
        "  ndims = value.shape.ndims\n",
        "\n",
        "  \"\"\"tf.tile documentation : https://www.tensorflow.org/api_docs/python/tf/tile\"\"\"\n",
        "  return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
        "\n",
        "def positions_for(tokens, past_length):\n",
        "  batch_size = tf.shape(tokens)[0]\n",
        "  nsteps = tf.shape(tokens)[1]\n",
        "  return expand_tile(past_length + tf.range(nsteps), batch_size)\n",
        "\n",
        "def model(hparams, X, Y=None, past=None, scope='model', reuse=False):\n",
        "  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
        "    results = {}\n",
        "    batch, sequence = shape_list(X)\n",
        "\n",
        "    if hparams.bert:\n",
        "      M = tf.greater(tf.random.uniform([batch, sequence]), hparams.bert_mask_prob)\n",
        "      M = tf.cast(M, tf.float32)\n",
        "\n",
        "    # What are these??\n",
        "    \"\"\"\n",
        "    Update :\n",
        "    Wpe = Position Embedding Matrix                 (Describes the position of a word)\n",
        "    Wte = Token Embedding Matrix                    (Describes the meaning of a word)\n",
        "    Wtet = Token Embedding Transpose Matrix         (Will be used to convert results of the transformer back into the\n",
        "                                                      pixels; just like transpose convolution)\n",
        "    \"\"\"\n",
        "    wpe = tf.compat.v1.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n",
        "                          initializer=tf.random_normal_initializer(stddev=0.01))\n",
        "    wte = tf.compat.v1.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
        "                          initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "    wtet = tf.compat.v1.get_variable('wtet', [hparams.n_vocab, hparams.n_embd],\n",
        "                          initializer=tf.random_normal_initializer(stddev=0.0))\n",
        "\n",
        "    past_length = 0 if past is None else tf.shape(past)[-2]\n",
        "\n",
        "    h = tf.gather(wte, X)\n",
        "    # tf.gather is just list slicing, see documentation for more info\n",
        "\n",
        "    if hparams.bert:\n",
        "      h = h*tf.expand_dims(M, 2)\n",
        "    else:\n",
        "      \"\"\"\n",
        "      FFFFF\n",
        "      This SOS is just \"Start of sentence\".\n",
        "      Wasted a lot of time in finding it out.\n",
        "\n",
        "      sos = start of sentence\n",
        "      sos_tok = start of sentence : token\n",
        "      \"\"\"\n",
        "\n",
        "      sos = tf.compat.v1.get_variable('sos', [hparams.n_embd],\n",
        "                            initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "\n",
        "      sos_tok = tf.ones([batch, 1, hparams.n_embd], dtype=tf.float32)*sos\n",
        "      h = tf.concat([sos_tok, h[:, :-1, :]], axis=1)\n",
        "\n",
        "    h += tf.gather(wpe, positions_for(X, past_length))\n",
        "\n",
        "    \"\"\"\n",
        "    h is the processed input ready to be fed into the transformer decoder\n",
        "    \"\"\"\n",
        "\n",
        "    # Transformer\n",
        "    presents = []\n",
        "    pasts = tf.unstack(past, axis=1) if past is not None else [None]*hparams.n_layer\n",
        "\n",
        "    assert len(pasts) == hparams.n_layer\n",
        "    for layer, past in enumerate(pasts):\n",
        "      h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n",
        "      # 'h%d' % layer : it is just python string formatting in c-style\n",
        "      #                 equivalent to f'h{layer}'\n",
        "\n",
        "      presents.append(present)\n",
        "\n",
        "    results['present'] = tf.stack(presents, axis=1)\n",
        "    h = norm(h, 'ln_f')\n",
        "\n",
        "    # Generative loss. Do tokens < n predict token n?\n",
        "    \"\"\"\n",
        "    Procedure : Flatten the results, convert them from tokens to pixels values again,\n",
        "                store as results, calculate the loss\n",
        "    \"\"\"\n",
        "    h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
        "    gen_logits = tf.matmul(h_flat, wtet, transpose_b = True)\n",
        "    gen_logits = tf.reshape(gen_logits, [batch, sequence, hparams.n_vocab])\n",
        "    results['gen_logits'] = gen_logits\n",
        "\n",
        "    gen_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=gen_logits, labels=X)\n",
        "\n",
        "    if hparams.bert:\n",
        "      IM = 1.0 - M\n",
        "      gen_losses = tf.reduce_sum(gen_losses*IM, axis=1)/tf.reduce_sum(IM, axis=1)\n",
        "      results['gen_loss'] = tf.reduce_mean(gen_losses)\n",
        "    else:\n",
        "      results['gen_loss'] = tf.reduce_mean(gen_losses)\n",
        "\n",
        "    # Classification loss.\n",
        "    with tf.compat.v1.variable_scope('clf', reuse=reuse):\n",
        "      classes = shape_list(Y)[1]\n",
        "      if hparams.clf:\n",
        "        wclf = tf.compat.v1.get_variable('wclf', [classes, hparams.n_embd],\n",
        "                              initializer=tf.random_normal_initializer(stddev=0.0))\n",
        "      else:\n",
        "        wclf = tf.zeros([classes, hparams.n_embd], dtype=tf.float32)\n",
        "\n",
        "    # Layer normalization\n",
        "    h = tf.reduce_mean(h, axis=1)   # average pool over sequence\n",
        "    clf_logits = tf.matmul(h, wclf, transpose_b=True)\n",
        "    clf_losses = tf.nn.softmax_cross_entropy_with_logits_v2(logits=clf_logits, labels=Y)\n",
        "\n",
        "    results['clf_loss'] = tf.reduce_mean(clf_losses)\n",
        "\n",
        "    correct = tf.equal(tf.argmax(clf_logits, -1), tf.argmax(Y, -1))\n",
        "    results['accuracy'] = tf.reduce_mean(tf.cast(correct, tf.float32))*100.0\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4Dljf1i-HV",
        "outputId": "dd7b7e55-42b0-442c-e54b-5055042f14f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import pickle\n",
        "import subprocess\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Some basic utilities\n",
        "\n",
        "def iter_data(*datas, n_batch=128, truncate=False, verbose=False, max_batches=float(\"inf\")):\n",
        "    n = len(datas[0])\n",
        "    if truncate:\n",
        "        n = (n//n_batch)*n_batch\n",
        "    n = min(n, max_batches*n_batch)\n",
        "    n_batches = 0\n",
        "    for i in tqdm(range(0, n, n_batch), total=n//n_batch, disable=not verbose, ncols=80, leave=False):\n",
        "        if n_batches >= max_batches: raise StopIteration\n",
        "        if len(datas) == 1:\n",
        "            yield datas[0][i:i+n_batch]\n",
        "        else:\n",
        "            yield (d[i:i+n_batch] for d in datas)\n",
        "        n_batches += 1\n",
        "\n",
        "def squared_euclidean_distance(a, b):\n",
        "    b = tf.transpose(b)\n",
        "    a2 = tf.reduce_sum(tf.square(a), axis=1, keepdims=True)\n",
        "    b2 = tf.reduce_sum(tf.square(b), axis=0, keepdims=True)\n",
        "    ab = tf.matmul(a, b)\n",
        "    d = a2 - 2*ab + b2\n",
        "    return d\n",
        "\n",
        "def color_quantize(x, np_clusters):\n",
        "    clusters = tf.Variable(np_clusters, dtype=tf.float32, trainable=False)\n",
        "    x = tf.reshape(x, [-1, 3])\n",
        "    d = squared_euclidean_distance(x, clusters)\n",
        "    return tf.argmin(d, 1)\n",
        "\n",
        "def count_parameters():\n",
        "    total_parameters = 0\n",
        "    for variable in tf.compat.v1.trainable_variables():\n",
        "        shape = variable.get_shape()\n",
        "        variable_parameters = 1\n",
        "        for dim in shape:\n",
        "            variable_parameters *= dim.value\n",
        "        total_parameters += variable_parameters\n",
        "    return total_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe0njVCUkza3",
        "outputId": "337117d7-4b70-4ecd-a631-b4d266906957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing run.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run.py\n",
        "\n",
        "# Running and Evaluating the model\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from imageio import imwrite\n",
        "from scipy.special import softmax\n",
        "from tensorflow.contrib.training import HParams\n",
        "from tqdm import tqdm\n",
        "\n",
        "from model import model\n",
        "from utils import iter_data, count_parameters\n",
        "\n",
        "\n",
        "\"\"\" This function won't be used just adding for the sake of completeness\"\"\"\n",
        "# \"\"\"\n",
        "def parse_arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  # data and I/O\n",
        "  parser.add_argument(\"--data_path\", type=str, default=\"/root/downloads/imagenet\")\n",
        "  parser.add_argument(\"--ckpt_path\", type=str, default=\"/root/downloads/model.ckpt-1000000\")\n",
        "  parser.add_argument(\"--color_cluster_path\", type=str, default=\"/root/downloads/kmeans_centers.npy\")\n",
        "  parser.add_argument(\"--save_dir\", type=str, default=\"/root/save/\")\n",
        "\n",
        "  # model\n",
        "  parser.add_argument(\"--n_embd\", type=int, default=512)\n",
        "  parser.add_argument(\"--n_head\", type=int, default=8)\n",
        "  parser.add_argument(\"--n_layer\", type=int, default=24)\n",
        "  parser.add_argument(\"--n_px\", type=int, default=32, help=\"image height or width in pixels\")\n",
        "  parser.add_argument(\"--n_vocab\", type=int, default=512, help=\"possible values for each pixel\")\n",
        "\n",
        "  parser.add_argument(\"--bert\", action=\"store_true\", help=\"use the bert objective (default: autoregressive)\")\n",
        "  parser.add_argument(\"--bert_mask_prob\", type=float, default=0.15)\n",
        "  parser.add_argument(\"--clf\", action=\"store_true\", help=\"add a learnable classification head\")\n",
        "\n",
        "  # parallelism\n",
        "  parser.add_argument(\"--n_sub_batch\", type=int, default=8, help=\"per-gpu batch_size\")\n",
        "  parser.add_argument(\"--n_gpu\", type=int, default=8, help=\"number of gpus to distribute training across\")\n",
        "\n",
        "  # mode\n",
        "  parser.add_argument(\"--eval\", action=\"store_true\", help=\"evaluates the model, requires a checkpoint and dataset\")\n",
        "  parser.add_argument(\"--sample\", action=\"store_true\", help=\"samples the model, requires a checkpoint and clusters\")\n",
        "\n",
        "  # reproducibility\n",
        "  parser.add_argument(\"--seed\", type=int, default=42, help=\"seed for random, np, tf\")\n",
        "\n",
        "  args = parser.parse_args()\n",
        "  print(\"input args:\\n\", json.dumps(vars(args), indent=4, separators=(\",\", \":\")))\n",
        "\n",
        "  return args\n",
        "# \"\"\"\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "def load_data(data_path):\n",
        "  trX = np.load(f'{data_path}_trX.npy')\n",
        "  trY = np.load(f'{data_path}_trY.npy')\n",
        "  vaX = np.load(f'{data_path}_vaX.npy')\n",
        "  vaY = np.load(f'{data_path}_vaY.npy')\n",
        "  teX = np.load(f'{data_path}_teX.npy')\n",
        "  teY = np.load(f'{data_path}_teY.npy')\n",
        "\n",
        "  return (trX, trY), (vaX, vaY), (teX, teY)\n",
        "\n",
        "def set_hparams(args):\n",
        "    return HParams(\n",
        "        n_ctx=args.n_px*args.n_px,\n",
        "        n_embd=args.n_embd,\n",
        "        n_head=args.n_head,\n",
        "        n_layer=args.n_layer,\n",
        "        n_vocab=args.n_vocab,\n",
        "        bert=args.bert,\n",
        "        bert_mask_prob=args.bert_mask_prob,\n",
        "        clf=args.clf,\n",
        "    )\n",
        "\n",
        "\n",
        "def create_model(x, y, n_gpu, hparams):\n",
        "    gen_logits = []\n",
        "    gen_loss = []\n",
        "    clf_loss = []\n",
        "    tot_loss = []\n",
        "    accuracy = []\n",
        "\n",
        "    trainable_params = None\n",
        "    for i in range(n_gpu):\n",
        "        with tf.device(\"/gpu:%d\" % i):\n",
        "            results = model(hparams, x[i], y[i], reuse=(i != 0))\n",
        "\n",
        "            gen_logits.append(results[\"gen_logits\"])\n",
        "            gen_loss.append(results[\"gen_loss\"])\n",
        "            clf_loss.append(results[\"clf_loss\"])\n",
        "\n",
        "            if hparams.clf:\n",
        "                tot_loss.append(results[\"gen_loss\"] + results[\"clf_loss\"])\n",
        "            else:\n",
        "                tot_loss.append(results[\"gen_loss\"])\n",
        "\n",
        "            accuracy.append(results[\"accuracy\"])\n",
        "\n",
        "            if i == 0:\n",
        "                trainable_params = tf.compat.v1.trainable_variables()\n",
        "                print(\"trainable parameters:\", count_parameters())\n",
        "\n",
        "    return trainable_params, gen_logits, gen_loss, clf_loss, tot_loss, accuracy\n",
        "\n",
        "\n",
        "def reduce_mean(gen_loss, clf_loss, tot_loss, accuracy, n_gpu):\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "        for i in range(1, n_gpu):\n",
        "            gen_loss[0] += gen_loss[i]\n",
        "            clf_loss[0] += clf_loss[i]\n",
        "            tot_loss[0] += tot_loss[i]\n",
        "            accuracy[0] += accuracy[i]\n",
        "        gen_loss[0] /= n_gpu\n",
        "        clf_loss[0] /= n_gpu\n",
        "        tot_loss[0] /= n_gpu\n",
        "        accuracy[0] /= n_gpu\n",
        "\n",
        "\n",
        "def evaluate(sess, evX, evY, X, Y, gen_loss, clf_loss, accuracy, n_batch, desc, permute=False):\n",
        "    metrics = []\n",
        "    for xmb, ymb in iter_data(evX, evY, n_batch=n_batch, truncate=True, verbose=True):\n",
        "        metrics.append(sess.run([gen_loss[0], clf_loss[0], accuracy[0]], {X: xmb, Y: ymb}))\n",
        "    eval_gen_loss, eval_clf_loss, eval_accuracy = [np.mean(m) for m in zip(*metrics)]\n",
        "    print(f\"{desc} gen: {eval_gen_loss:.4f} clf: {eval_clf_loss:.4f} acc: {eval_accuracy:.2f}\")\n",
        "\n",
        "\n",
        "# naive sampler without caching\n",
        "def sample(sess, X, gen_logits, n_sub_batch, n_gpu, n_px, n_vocab, clusters, save_dir):\n",
        "    samples = np.zeros([n_gpu * n_sub_batch, n_px * n_px], dtype=np.int32)\n",
        "\n",
        "    for i in tqdm(range(n_px * n_px), ncols=80, leave=False):\n",
        "        np_gen_logits = sess.run(gen_logits, {X: samples})\n",
        "        for j in range(n_gpu):\n",
        "            p = softmax(np_gen_logits[j][:, i, :], axis=-1)  # logits to probabilities\n",
        "            for k in range(n_sub_batch):\n",
        "                c = np.random.choice(n_vocab, p=p[k])  # choose based on probabilities\n",
        "                samples[j * n_sub_batch + k, i] = c\n",
        "\n",
        "    # dequantize\n",
        "    samples = [np.reshape(np.rint(127.5 * (clusters[s] + 1.0)), [32, 32, 3]).astype(np.uint8) for s in samples]\n",
        "\n",
        "    # write to png\n",
        "    for i in range(n_gpu * n_sub_batch):\n",
        "        imwrite(f\"{args.save_dir}/sample_{i}.png\", samples[i])\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    n_batch = args.n_sub_batch * args.n_gpu\n",
        "\n",
        "    if args.data_path.endswith(\"cifar10\"):\n",
        "        n_class = 10\n",
        "    elif args.data_path.endswith(\"imagenet\"):\n",
        "        n_class = 1000\n",
        "    else:\n",
        "        raise ValueError(\"Dataset not supported.\")\n",
        "\n",
        "    X = tf.compat.v1.placeholder(tf.int32, [n_batch, args.n_px * args.n_px])\n",
        "    Y = tf.compat.v1.placeholder(tf.float32, [n_batch, n_class])\n",
        "\n",
        "    x = tf.split(X, args.n_gpu, 0)\n",
        "    y = tf.split(Y, args.n_gpu, 0)\n",
        "\n",
        "    hparams = set_hparams(args)\n",
        "    trainable_params, gen_logits, gen_loss, clf_loss, tot_loss, accuracy = create_model(x, y, args.n_gpu, hparams)\n",
        "    reduce_mean(gen_loss, clf_loss, tot_loss, accuracy, args.n_gpu)\n",
        "\n",
        "    saver = tf.compat.v1.train.Saver(var_list=[tp for tp in trainable_params if not 'clf' in tp.name])\n",
        "    with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        saver.restore(sess, args.ckpt_path)\n",
        "\n",
        "        if args.eval:\n",
        "          (trX, trY), (vaX, vaY), (teX, teY) = load_data(args.data_path)\n",
        "          evaluate(sess, trX[:len(vaX)], trY[:len(vaY)], X, Y, gen_loss, clf_loss, accuracy, n_batch, \"train\")\n",
        "          evaluate(sess, vaX, vaY, X, Y, gen_loss, clf_loss, accuracy, n_batch, \"valid\")\n",
        "          evaluate(sess, teX, teY, X, Y, gen_loss, clf_loss, accuracy, n_batch, \"test\")\n",
        "\n",
        "        if args.sample:\n",
        "            if not os.path.exists(args.save_dir):\n",
        "                os.makedirs(args.save_dir)\n",
        "            clusters = np.load(args.color_cluster_path)\n",
        "            sample(sess, X, gen_logits, args.n_sub_batch, args.n_gpu, args.n_px, args.n_vocab, clusters, args.save_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_arguments()\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTLJenEgGTsw",
        "outputId": "eca18db9-2f9c-476e-96e1-bcfd4c7129bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing download.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile download.py\n",
        "\n",
        "# Data Retrieval\n",
        "# This part should be removed later on\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def parse_arguments():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument(\"--download_dir\", type=str, default=\"/root/downloads/\")\n",
        "\n",
        "    parser.add_argument(\"--bert\", action=\"store_true\", help=\"download a bert model (default: ar)\")\n",
        "    parser.add_argument(\"--model\", type=str, choices=[\"s\", \"m\", \"l\"], help=\"parameter counts are s:76M, m:455M, l:1362M\")\n",
        "    parser.add_argument(\"--ckpt\", type=str, choices=[\"131000\", \"262000\", \"524000\", \"1000000\"])\n",
        "    parser.add_argument(\"--clusters\", action=\"store_true\", help=\"download the color clusters file\")\n",
        "    parser.add_argument(\"--dataset\", type=str, choices=[\"imagenet\", \"cifar10\"])\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    print(\"input args:\\n\", json.dumps(vars(args), indent=4, separators=(\",\", \":\")))\n",
        "    return args\n",
        "\n",
        "def main(args):\n",
        "    if not os.path.exists(args.download_dir):\n",
        "        os.makedirs(args.download_dir)\n",
        "\n",
        "    urls = []\n",
        "\n",
        "    # download the checkpoint\n",
        "    if args.model and args.ckpt:\n",
        "        base_url = f\"https://openaipublic.blob.core.windows.net/image-gpt/checkpoints/igpt-{args.model}{'-bert' if args.bert else ''}/{args.ckpt}\"\n",
        "\n",
        "        size_to_shards = {\"s\": 32, \"m\": 32, \"l\": 64}\n",
        "        shards = size_to_shards[args.model]\n",
        "\n",
        "        for filename in [f\"model.ckpt-{args.ckpt}.data-{i:05d}-of-{shards:05d}\" for i in range(shards)]:\n",
        "            urls.append(f\"{base_url}/{filename}\")\n",
        "        urls.append(f\"{base_url}/model.ckpt-{args.ckpt}.index\")\n",
        "        urls.append(f\"{base_url}/model.ckpt-{args.ckpt}.meta\")\n",
        "\n",
        "    # download the color clusters file\n",
        "    if args.clusters:\n",
        "        urls.append(\"https://openaipublic.blob.core.windows.net/image-gpt/color-clusters/kmeans_centers.npy\")\n",
        "\n",
        "    # download color clustered dataset\n",
        "    if args.dataset:\n",
        "        for split in [\"trX\", \"trY\", \"vaX\", \"vaY\", \"teX\", \"teY\"]:\n",
        "            urls.append(f\"https://openaipublic.blob.core.windows.net/image-gpt/datasets/{args.dataset}_{split}.npy\")\n",
        "\n",
        "    # run the download\n",
        "    for url in urls:\n",
        "        filename = url.split(\"/\")[-1]\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(f\"{args.download_dir}/{filename}\", \"wb\") as f:\n",
        "            file_size = int(r.headers[\"content-length\"])\n",
        "            chunk_size = 1000\n",
        "            with tqdm(ncols=80, desc=\"Fetching \" + filename, total=file_size, unit_scale=True) as pbar:\n",
        "                # 1k for chunk_size, since Ethernet packet size is around 1500 bytes\n",
        "                for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(chunk_size)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_arguments()\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFI-zBz49lBt"
      },
      "source": [
        "Code Ready.  \n",
        "Rough Work below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DA1o84DtEoU",
        "outputId": "b68abd5f-99e3-45b6-ec7e-877071d4d530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input args:\n",
            " {\n",
            "    \"download_dir\":\"/root/downloads/\",\n",
            "    \"bert\":false,\n",
            "    \"model\":\"s\",\n",
            "    \"ckpt\":\"262000\",\n",
            "    \"clusters\":false,\n",
            "    \"dataset\":null\n",
            "}\n",
            "Fetching model.ckpt-262000.data-00000-of-00032: 1.00kit [00:00, 819kit/s]       \n",
            "Fetching model.ckpt-262000.data-00001-of-00032: 31.5Mit [00:06, 5.20Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00002-of-00032: 28.3Mit [00:04, 5.82Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00003-of-00032: 28.3Mit [00:05, 5.12Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00004-of-00032: 28.3Mit [00:05, 5.63Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00005-of-00032: 31.5Mit [00:05, 5.36Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00006-of-00032: 30.4Mit [00:05, 5.32Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00007-of-00032: 28.3Mit [00:04, 6.02Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00008-of-00032: 31.5Mit [00:05, 5.42Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00009-of-00032: 29.4Mit [00:06, 4.57Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00010-of-00032: 31.5Mit [00:05, 5.78Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00011-of-00032: 31.5Mit [00:06, 5.12Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00012-of-00032: 30.4Mit [00:05, 5.38Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00013-of-00032: 28.3Mit [00:04, 6.45Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00014-of-00032: 31.5Mit [00:05, 5.47Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00015-of-00032: 32.5Mit [00:16, 1.92Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00016-of-00032: 31.5Mit [00:05, 5.29Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00017-of-00032: 28.3Mit [00:05, 5.56Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00018-of-00032: 29.4Mit [00:05, 4.96Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00019-of-00032: 28.3Mit [00:04, 5.79Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00020-of-00032: 28.3Mit [00:06, 4.37Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00021-of-00032: 28.3Mit [00:05, 4.79Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00022-of-00032: 30.4Mit [00:08, 3.65Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00023-of-00032: 30.4Mit [00:05, 5.40Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00024-of-00032: 29.4Mit [00:05, 5.47Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00025-of-00032: 28.3Mit [00:04, 6.11Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00026-of-00032: 28.3Mit [00:04, 5.81Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00027-of-00032: 29.4Mit [00:06, 4.83Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00028-of-00032: 29.4Mit [00:05, 5.04Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00029-of-00032: 29.4Mit [00:05, 5.18Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00030-of-00032: 28.3Mit [00:05, 5.59Mit/s]      \n",
            "Fetching model.ckpt-262000.data-00031-of-00032: 28.3Mit [00:05, 4.95Mit/s]      \n",
            "Fetching model.ckpt-262000.index: 10.0kit [00:00, 6.79Mit/s]                    \n",
            "Fetching model.ckpt-262000.meta: 18.4Mit [00:03, 5.42Mit/s]                     \n"
          ]
        }
      ],
      "source": [
        "!python3 download.py --model s --ckpt 262000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J1qnN6GBuXXp",
        "outputId": "39f636a1-54b2-4ab1-9808-01bcf224f53b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input args:\n",
            " {\n",
            "    \"download_dir\":\"/root/downloads/\",\n",
            "    \"bert\":false,\n",
            "    \"model\":null,\n",
            "    \"ckpt\":null,\n",
            "    \"clusters\":false,\n",
            "    \"dataset\":\"cifar10\"\n",
            "}\n",
            "Fetching cifar10_trX.npy: 184Mit [00:30, 6.07Mit/s]                             \n",
            "Fetching cifar10_trY.npy: 1.80Mit [00:01, 1.24Mit/s]                            \n",
            "Fetching cifar10_vaX.npy: 20.5Mit [00:03, 5.81Mit/s]                            \n",
            "Fetching cifar10_vaY.npy: 201kit [00:00, 284kit/s]                              \n",
            "Fetching cifar10_teX.npy: 41.0Mit [00:07, 5.50Mit/s]                            \n",
            "Fetching cifar10_teY.npy: 401kit [00:00, 443kit/s]                              \n"
          ]
        }
      ],
      "source": [
        "!python3 download.py --dataset cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ViFy-DqueK6",
        "outputId": "6d7577d3-e11e-4680-e377-15e8a3f82312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input args:\n",
            " {\n",
            "    \"download_dir\":\"/root/downloads/\",\n",
            "    \"bert\":false,\n",
            "    \"model\":null,\n",
            "    \"ckpt\":null,\n",
            "    \"clusters\":true,\n",
            "    \"dataset\":null\n",
            "}\n",
            "Fetching kmeans_centers.npy: 7.00kit [00:00, 5.15Mit/s]                         \n"
          ]
        }
      ],
      "source": [
        "!python3 download.py --clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "beJfAUiE0lSe",
        "outputId": "68d7f9a2-26da-4e43-e481-27562b1820c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cifar10_teX.npy\t\t\t       model.ckpt-262000.data-00014-of-00032\n",
            "cifar10_teY.npy\t\t\t       model.ckpt-262000.data-00015-of-00032\n",
            "cifar10_trX.npy\t\t\t       model.ckpt-262000.data-00016-of-00032\n",
            "cifar10_trY.npy\t\t\t       model.ckpt-262000.data-00017-of-00032\n",
            "cifar10_vaX.npy\t\t\t       model.ckpt-262000.data-00018-of-00032\n",
            "cifar10_vaY.npy\t\t\t       model.ckpt-262000.data-00019-of-00032\n",
            "kmeans_centers.npy\t\t       model.ckpt-262000.data-00020-of-00032\n",
            "model.ckpt-262000.data-00000-of-00032  model.ckpt-262000.data-00021-of-00032\n",
            "model.ckpt-262000.data-00001-of-00032  model.ckpt-262000.data-00022-of-00032\n",
            "model.ckpt-262000.data-00002-of-00032  model.ckpt-262000.data-00023-of-00032\n",
            "model.ckpt-262000.data-00003-of-00032  model.ckpt-262000.data-00024-of-00032\n",
            "model.ckpt-262000.data-00004-of-00032  model.ckpt-262000.data-00025-of-00032\n",
            "model.ckpt-262000.data-00005-of-00032  model.ckpt-262000.data-00026-of-00032\n",
            "model.ckpt-262000.data-00006-of-00032  model.ckpt-262000.data-00027-of-00032\n",
            "model.ckpt-262000.data-00007-of-00032  model.ckpt-262000.data-00028-of-00032\n",
            "model.ckpt-262000.data-00008-of-00032  model.ckpt-262000.data-00029-of-00032\n",
            "model.ckpt-262000.data-00009-of-00032  model.ckpt-262000.data-00030-of-00032\n",
            "model.ckpt-262000.data-00010-of-00032  model.ckpt-262000.data-00031-of-00032\n",
            "model.ckpt-262000.data-00011-of-00032  model.ckpt-262000.index\n",
            "model.ckpt-262000.data-00012-of-00032  model.ckpt-262000.meta\n",
            "model.ckpt-262000.data-00013-of-00032\n"
          ]
        }
      ],
      "source": [
        "!ls /root/downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6dc0Nn9JumD6",
        "outputId": "ad6d24b3-41c3-4f43-a54d-e80c0e9cec19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"run.py\", line 17, in <module>\n",
            "    from tensorflow.contrib.training import HParams\n",
            "ModuleNotFoundError: No module named 'tensorflow.contrib'\n"
          ]
        }
      ],
      "source": [
        "!python3 run.py --eval --ckpt_path /root/downloads/model.ckpt-262000 --data_path /root/downloads/cifar10 --n_embd 512 --n_head 8 --n_layer 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhB8BaBLMpcC",
        "outputId": "b86c545a-57bd-4489-dec6-70cee00adb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input args:\n",
            " {\n",
            "    \"data_path\":\"/root/downloads/cifar10\",\n",
            "    \"ckpt_path\":\"/root/downloads/model.ckpt-262000\",\n",
            "    \"color_cluster_path\":\"/root/downloads/kmeans_centers.npy\",\n",
            "    \"save_dir\":\"/root/save/\",\n",
            "    \"n_embd\":512,\n",
            "    \"n_head\":8,\n",
            "    \"n_layer\":24,\n",
            "    \"n_px\":32,\n",
            "    \"n_vocab\":512,\n",
            "    \"bert\":false,\n",
            "    \"bert_mask_prob\":0.15,\n",
            "    \"clf\":false,\n",
            "    \"n_sub_batch\":8,\n",
            "    \"n_gpu\":1,\n",
            "    \"eval\":false,\n",
            "    \"sample\":true,\n",
            "    \"seed\":42\n",
            "}\n",
            "trainable parameters: 76571648\n",
            "2021-11-02 15:10:45.565334: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-11-02 15:10:45.565575: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56080091cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-02 15:10:45.565613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-11-02 15:10:45.569377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-11-02 15:10:45.701559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 15:10:45.702507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56080091d2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-02 15:10:45.702563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-11-02 15:10:45.702810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 15:10:45.703515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-11-02 15:10:45.704129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-02 15:10:45.707024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-11-02 15:10:45.708244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-11-02 15:10:45.708945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-11-02 15:10:45.711338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-11-02 15:10:45.721095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-11-02 15:10:45.729999: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-11-02 15:10:45.730144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 15:10:45.731008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 15:10:45.731723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-11-02 15:10:45.731821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-11-02 15:10:45.733282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-11-02 15:10:45.733313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-11-02 15:10:45.733329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-11-02 15:10:45.733487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 15:10:45.734336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-11-02 15:10:45.735062: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-11-02 15:10:45.735112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "  0%|                                                  | 0/1024 [00:00<?, ?it/s]2021-11-02 15:10:51.620494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 run.py --sample --ckpt_path /root/downloads/model.ckpt-262000 --data_path /root/downloads/cifar10 --n_embd 512 --n_head 8 --n_layer 24 --n_gpu 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "NVuVwZEBUuqU",
        "outputId": "600cb2ea-b0b4-4841-b999-c73e47dabe19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: root/save/ (stored 0%)\n",
            "  adding: root/save/sample_3.png (stored 0%)\n",
            "  adding: root/save/sample_5.png (stored 0%)\n",
            "  adding: root/save/sample_2.png (stored 0%)\n",
            "  adding: root/save/sample_0.png (stored 0%)\n",
            "  adding: root/save/sample_1.png (stored 0%)\n",
            "  adding: root/save/sample_7.png (stored 0%)\n",
            "  adding: root/save/sample_6.png (stored 0%)\n",
            "  adding: root/save/sample_4.png (stored 0%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_cf66f9d4-0ea4-4802-9d25-901a54f3f34d\", \"save.zip\", 17886)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /root/save.zip /root/save\n",
        "files.download('/root/save.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}